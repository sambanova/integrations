{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<picture>\n",
                "<a href=\"https://sambanova.ai/\"\\>\n",
                "<source media=\"(prefers-color-scheme: dark)\" srcset=\"../../images/SambaNova-light-logo-1.png\" height=\"60\">\n",
                "<img alt=\"SambaNova logo\" src=\"../../images/SambaNova-dark-logo-1.png\" height=\"60\">\n",
                "</picture>\n",
                "</a>\n",
                "\n",
                "# Company Research \n",
                "\n",
                "Adapted from the same [Autogen example](https://microsoft.github.io/autogen/dev//user-guide/agentchat-user-guide/examples/travel-planning.html).\n",
                "\n",
                "Conducting company research, or competitive analysis, is a critical part of any business strategy. In this notebook, we will demonstrate how to create a team of agents to address this task. While there are many ways to translate a task into an agentic implementation, we will explore a sequential approach. We will create agents corresponding to steps in the research process and give them tools to perform their tasks.\n",
                "\n",
                "- **Search Agent**: Searches the web for information about a company. Will have access to a search engine API tool to retrieve search results.\n",
                "- **Stock Analysis Agent**: Retrieves the company's stock information from a financial data API, computes basic statistics (current price, 52-week high, 52-week low, etc.), and generates a plot of the stock price year-to-date, saving it to a file. Will have access to a financial data API tool to retrieve stock information.\n",
                "- **Report Agent**: Generates a report based on the information collected by the search and stock analysis agents. \n",
                "\n",
                "First, let's import the necessary modules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from autogen_agentchat.agents import AssistantAgent\n",
                "from autogen_agentchat.conditions import TextMentionTermination\n",
                "from autogen_agentchat.teams import RoundRobinGroupChat\n",
                "from autogen_agentchat.ui import Console\n",
                "from autogen_core.tools import FunctionTool\n",
                "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Defining Tools \n",
                "\n",
                "Next, we will define the tools that the agents will use to perform their tasks. We will create a [Google Search API key](https://support.google.com/googleapi/answer/6158862?hl=en) and set up a [Google Search Engine](https://programmablesearchengine.google.com/controlpanel/create) to get the Search Engine ID, both are used by the Google Search API to search the web for information about a company. Don't forget to enable the Custom Search API in your Google Cloud Console too. We will also create a  `analyze_stock` function that uses the `yfinance` library to retrieve stock information for a company. \n",
                "\n",
                "Finally, we will wrap these functions into a `FunctionTool` class that will allow us to use them as tools in our agents. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "import getpass\n",
                "load_dotenv('../../.env')\n",
                "\n",
                "import os\n",
                "\n",
                "# Setting up SambaNova Cloud credentials\n",
                "sn_api_url = os.getenv(\"SAMBANOVA_URL\") # It has to be like this `https://api.sambanova.ai/v1`\n",
                "sn_api_key = os.getenv(\"SAMBANOVA_API_KEY\")\n",
                "\n",
                "if not sn_api_key:\n",
                "    sn_api_key = getpass.getpass(\"insert your SambaNova API Key\") \n",
                "    \n",
                "if not sn_api_url:\n",
                "    sn_api_url = \"https://api.sambanova.ai/v1\"\n",
                "\n",
                "# Setting up Google Search credentials    \n",
                "ggl_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
                "ggl_search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
                "\n",
                "if not ggl_api_key:\n",
                "    ggl_api_key = getpass.getpass(\"insert your Google Search API key\") \n",
                "    \n",
                "if not ggl_search_engine_id:\n",
                "    ggl_search_engine_id = getpass.getpass(\"insert your Google Search ID\") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
                "    import os\n",
                "    import time\n",
                "\n",
                "    import requests\n",
                "    from bs4 import BeautifulSoup\n",
                "\n",
                "    if not ggl_api_key or not ggl_search_engine_id:\n",
                "        raise ValueError(\"API key or Search Engine ID not found in environment variables\")\n",
                "\n",
                "    url = \"https://customsearch.googleapis.com/customsearch/v1\"\n",
                "    params = {\"key\": str(ggl_api_key), \"cx\": str(ggl_search_engine_id), \"q\": str(query), \"num\": str(num_results)}\n",
                "\n",
                "    response = requests.get(url, params=params)\n",
                "    \n",
                "    if response.status_code != 200:\n",
                "        print(response.json())\n",
                "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
                "\n",
                "    results = response.json().get(\"items\", [])\n",
                "\n",
                "    def get_page_content(url: str) -> str:\n",
                "        try:\n",
                "            response = requests.get(url, timeout=10)\n",
                "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
                "            text = soup.get_text(separator=\" \", strip=True)\n",
                "            words = text.split()\n",
                "            content = \"\"\n",
                "            for word in words:\n",
                "                if len(content) + len(word) + 1 > max_chars:\n",
                "                    break\n",
                "                content += \" \" + word\n",
                "            return content.strip()\n",
                "        except Exception as e:\n",
                "            print(f\"Error fetching {url}: {str(e)}\")\n",
                "            return \"\"\n",
                "\n",
                "    enriched_results = []\n",
                "    for item in results:\n",
                "        body = get_page_content(item[\"link\"])\n",
                "        enriched_results.append(\n",
                "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item[\"snippet\"], \"body\": body}\n",
                "        )\n",
                "        time.sleep(1)  # Be respectful to the servers\n",
                "\n",
                "    return enriched_results\n",
                "\n",
                "\n",
                "def analyze_stock(ticker: str) -> dict:  # type: ignore[type-arg]\n",
                "    import os\n",
                "    from datetime import datetime, timedelta\n",
                "\n",
                "    import matplotlib.pyplot as plt\n",
                "    import numpy as np\n",
                "    import pandas as pd\n",
                "    import yfinance as yf\n",
                "    from pytz import timezone  # type: ignore\n",
                "\n",
                "    stock = yf.Ticker(ticker)\n",
                "\n",
                "    # Get historical data (1 year of data to ensure we have enough for 200-day MA)\n",
                "    end_date = datetime.now(timezone(\"UTC\"))\n",
                "    start_date = end_date - timedelta(days=365)\n",
                "    hist = stock.history(start=start_date, end=end_date)\n",
                "\n",
                "    # Ensure we have data\n",
                "    if hist.empty:\n",
                "        return {\"error\": \"No historical data available for the specified ticker.\"}\n",
                "\n",
                "    # Compute basic statistics and additional metrics\n",
                "    current_price = stock.info.get(\"currentPrice\", hist[\"Close\"].iloc[-1])\n",
                "    year_high = stock.info.get(\"fiftyTwoWeekHigh\", hist[\"High\"].max())\n",
                "    year_low = stock.info.get(\"fiftyTwoWeekLow\", hist[\"Low\"].min())\n",
                "\n",
                "    # Calculate 50-day and 200-day moving averages\n",
                "    ma_50 = hist[\"Close\"].rolling(window=50).mean().iloc[-1]\n",
                "    ma_200 = hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
                "\n",
                "    # Calculate YTD price change and percent change\n",
                "    ytd_start = datetime(end_date.year, 1, 1, tzinfo=timezone(\"UTC\"))\n",
                "    ytd_data = hist.loc[ytd_start:]  # type: ignore[misc]\n",
                "    if not ytd_data.empty:\n",
                "        price_change = ytd_data[\"Close\"].iloc[-1] - ytd_data[\"Close\"].iloc[0]\n",
                "        percent_change = (price_change / ytd_data[\"Close\"].iloc[0]) * 100\n",
                "    else:\n",
                "        price_change = percent_change = np.nan\n",
                "\n",
                "    # Determine trend\n",
                "    if pd.notna(ma_50) and pd.notna(ma_200):\n",
                "        if ma_50 > ma_200:\n",
                "            trend = \"Upward\"\n",
                "        elif ma_50 < ma_200:\n",
                "            trend = \"Downward\"\n",
                "        else:\n",
                "            trend = \"Neutral\"\n",
                "    else:\n",
                "        trend = \"Insufficient data for trend analysis\"\n",
                "\n",
                "    # Calculate volatility (standard deviation of daily returns)\n",
                "    daily_returns = hist[\"Close\"].pct_change().dropna()\n",
                "    volatility = daily_returns.std() * np.sqrt(252)  # Annualized volatility\n",
                "\n",
                "    # Create result dictionary\n",
                "    result = {\n",
                "        \"ticker\": ticker,\n",
                "        \"current_price\": current_price,\n",
                "        \"52_week_high\": year_high,\n",
                "        \"52_week_low\": year_low,\n",
                "        \"50_day_ma\": ma_50,\n",
                "        \"200_day_ma\": ma_200,\n",
                "        \"ytd_price_change\": price_change,\n",
                "        \"ytd_percent_change\": percent_change,\n",
                "        \"trend\": trend,\n",
                "        \"volatility\": volatility,\n",
                "    }\n",
                "\n",
                "    # Convert numpy types to Python native types for better JSON serialization\n",
                "    for key, value in result.items():\n",
                "        if isinstance(value, np.generic):\n",
                "            result[key] = value.item()\n",
                "\n",
                "    # Generate plot\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(hist.index, hist[\"Close\"], label=\"Close Price\")\n",
                "    plt.plot(hist.index, hist[\"Close\"].rolling(window=50).mean(), label=\"50-day MA\")\n",
                "    plt.plot(hist.index, hist[\"Close\"].rolling(window=200).mean(), label=\"200-day MA\")\n",
                "    plt.title(f\"{ticker} Stock Price (Past Year)\")\n",
                "    plt.xlabel(\"Date\")\n",
                "    plt.ylabel(\"Price ($)\")\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "\n",
                "    # Save plot to file\n",
                "    os.makedirs(\"coding\", exist_ok=True)\n",
                "    plot_file_path = f\"coding/{ticker}_stockprice.png\"\n",
                "    plt.savefig(plot_file_path)\n",
                "    print(f\"Plot saved as {plot_file_path}\")\n",
                "    result[\"plot_file_path\"] = plot_file_path\n",
                "\n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "google_search_tool = FunctionTool(\n",
                "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
                ")\n",
                "stock_analysis_tool = FunctionTool(analyze_stock, description=\"Analyze stock data and generate a plot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Defining Agents\n",
                "\n",
                "Next, we will define the agents that will perform the tasks. We will create a `search_agent` that searches the web for information about a company,  a `stock_analysis_agent` that retrieves stock information for a company, and a `report_agent` that generates a report based on the information collected by the other agents. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def define_agents():\n",
                "    search_agent = AssistantAgent(\n",
                "        name=\"Google_Search_Agent\",\n",
                "        model_client=OpenAIChatCompletionClient(\n",
                "            model=\"Meta-Llama-3.1-70B-Instruct\", \n",
                "            base_url=sn_api_url, \n",
                "            api_key=sn_api_key, \n",
                "            model_info={\n",
                "                'json_output': False, \n",
                "                'function_calling': True, \n",
                "                'family': 'unknown', \n",
                "                'vision': False\n",
                "            }),\n",
                "        tools=[google_search_tool],\n",
                "        description=\"Search Google for information, returns top 2 results with a snippet and body content\",\n",
                "        system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
                "    )\n",
                "\n",
                "    stock_analysis_agent = AssistantAgent(\n",
                "        name=\"Stock_Analysis_Agent\",\n",
                "        model_client=OpenAIChatCompletionClient(\n",
                "            model=\"Meta-Llama-3.1-70B-Instruct\", \n",
                "            base_url=sn_api_url, \n",
                "            api_key=sn_api_key, \n",
                "            model_info={\n",
                "                'json_output': False, \n",
                "                'function_calling': True, \n",
                "                'family': 'unknown', \n",
                "                'vision': False\n",
                "            }),\n",
                "        tools=[stock_analysis_tool],\n",
                "        description=\"Analyze stock data and generate a plot\",\n",
                "        system_message=\"Perform data analysis.\",\n",
                "    )\n",
                "\n",
                "    report_agent = AssistantAgent(\n",
                "        name=\"Report_Agent\",\n",
                "        model_client=OpenAIChatCompletionClient(\n",
                "            model=\"Meta-Llama-3.1-70B-Instruct\", \n",
                "            base_url=sn_api_url, \n",
                "            api_key=sn_api_key, \n",
                "            model_info={\n",
                "                'json_output': False, \n",
                "                'function_calling': True, \n",
                "                'family': 'unknown', \n",
                "                'vision': False\n",
                "            }),\n",
                "        description=\"Generate a report based the search and results of stock analysis\",\n",
                "        system_message=\"You are a helpful assistant that can generate a comprehensive report on a given topic based on search and stock analysis. When you done with generating the report, reply with TERMINATE.\",\n",
                "    )\n",
                "    \n",
                "    return search_agent, stock_analysis_agent, report_agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Creating the Team\n",
                "\n",
                "Finally, let's create a team of the three agents and set them to work on researching a company. We use `max_turns=3` to limit the number of turns to exactly the same number of agents in the team. This effectively makes the agents work in a sequential manner."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def run_team(task: str):\n",
                "    stock_analysis_agent, search_agent, report_agent = define_agents()\n",
                "    team = RoundRobinGroupChat([stock_analysis_agent, search_agent, report_agent], max_turns=3)\n",
                "    \n",
                "    stream = team.run_stream(task=task)\n",
                "    await Console(stream)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "task = \"Write a financial report on American airlines\"\n",
                "await run_team(task)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "task = \"Write a financial report on Apple\"\n",
                "await run_team(task)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "task = \"Write a financial report on Nvidia\"\n",
                "await run_team(task)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "autogen_venv",
            "language": "python",
            "name": "autogen_venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
