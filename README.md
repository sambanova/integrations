<a href="https://sambanova.ai/">
<picture>
 <source media="(prefers-color-scheme: dark)" srcset="./images/SambaNova-light-logo-1.png" height="60">
  <img alt="SambaNova logo" src="./images/SambaNova-dark-logo-1.png" height="60">
</picture>
</a>

# SambaNova Cloud Integrations

Welcome to the SambaNova Cloud API ecosystem, where everyday our fast inference models are expanding alongside the best tools in the developer community. Explore the partners available below and get started building\! 

### Need Assistance? 

If you have any suggestions of integrations or questions, please post on our [Community Page](https://community.sambanova.ai/) so we can follow up. 

## Integrations

| Company/Package | Type | Description | Access |
| :---- | :---- | :---- | :---- |
| **ADK** | Agent building and orchestration | The Agent Development Kit (ADK) is a modular, model-agnostic framework developed by Google for building AI agents | [Demo code](./adk/README.md)  |
| **Agno** | Agent building and orchestration | Agno is a lightweight framework for building multi-modal AI agents | [Documentation](https://docs.agno.com/models/sambanova)  |
| **AI Suite** | LLM frameworks  | AI Suite simplifies access to multiple large language models through a unified interface. | [Documentation](https://docs.sambanova.ai/cloud/docs/integrations/aisuite) |
| **AutoGen** | Agent building and orchestration | AutoGen is an open-source tool that defines agents, integrates LLMs, and handles task termination.  | [Demo code](./autogen/) |
| **Browser Use** | Tool and Browser Use | Browser Use is an open-source project enabling AI agents to control web browsers, facilitating tasks like automated web navigation and data extraction. | [Documentation](https://docs.browser-use.com/quickstart) |
| **Camel** | Agent building and orchestration | Camel AI is an open-source framework for intelligent agents, and supports building, customizing, and deploying multi-agent systems.   | [Demo code](./camel/) |
| **Cline** | Coding assistants | Cline is a coding assistant tool that streamlines workflows, offers account management features, and optimizes provider routing for developers. | [Documentation](https://docs.cline.bot/getting-started/getting-started-new-coders) |
| **Continue** | Coding assistants | Continue is an open-source coding assistant platform to modify and optimize coding within IDE. | [Documentation](./continue) |
| **CrewAI** | Agent building and orchestration| CrewAI is an open-source framework for making automated workflows with agents. | [Demo code](./crewai_integration/) |
| **DataRobot** | Llm gateway and orchestration| DataRobot is a platform for deploying and orchestrating custom machine learning and LLM workflows with built-in governance and evaluation tools. | [Documentation](./datarobot) |
| **Dify** | Low-code platforms | Dify is a low-code platform to build and deploy AI applications. | [Documentation](https://docs.sambanova.ai/cloud/docs/integrations/dify) |
| **Docker Compose for agents** | Agent building and orchestration | Docker Compose facilitate the development, deployment, and management of AI agentic applications | [Demo Code](./docker-compose-for-agents/) |
| **Google Integration** | Others | App Scripts intended for those with SambaCloud API keys to integrate LLMs into Google Workspaces  | [Documentation](./google_integration/) |
| **Gradio** | LLM frameworks | Gradio is an open-source Python package that allows users to create interactive web apps for machine learning models, APIs, and Python functions.  | [Demo code](https://github.com/gradio-app/sambanova-gradio) |
| **Haystack** | LLM frameworks | Haystack is an open-source end-to-end framework that enables modular development of production-ready LLM applications.  | [Demo code](./haystack/) |
| **Hugging Face**  | LLM frameworks | Hugging Face is a platform for building, training, and deploying open-source models.  | [Documentation](https://huggingface.co/docs/huggingface_hub/main/en/package_reference/inference_client) |
| **Inspect AI** | LLM Evaluation | Inspect can be used for a broad range of evaluations that measure coding, agentic tasks, reasoning, knowledge, behavior, and multi-modal understanding. | [Documentation](https://inspect.aisi.org.uk/) |
| **Instructor** | Tool and Browser Use | Instructor enhances LLM interactions by enabling structured data extraction, multi-language compatibility, and parallel tool calling. | [Demo code](./instructor/) |
| **Kilocode** | Coding assistants | Kilocode is an AI-powered autonomous assistant for planning, building, and fixing code. It is a superset of Roo, Cline and their own features. | [Documentation](https://kilocode.ai/docs/) |
| **LangChain** | LLM frameworks | Langchain implements a standard interface for LLMs to simplify development, productization, and deployment. | [Documentation](https://python.langchain.com/docs/integrations/providers/sambanova/) |
| **Langflow** | Low-code platforms | Langflow is a visual framework for building multi-agent and RAG applications. | [Documentation](https://docs.langflow.org/components-models#sambanova) |
| **LangGraph** | LLM frameworks | LangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. | [Demo code](./langgraph) |
| **LlamaIndex** | LLM frameworks | LlamaIndex is an orchestration framework to rapidly deploy LLM applications. | [Demo code](./llamaindex) |
| **LiteLLM** | LLM frameworks | LiteLLM is an open-source Python library that provides a unified interface for accessing LLMs, translating inputs and mapping exceptions. | [Documentation](https://docs.litellm.ai/docs/providers/sambanova) |
| **Livekit** | LLM framework | LiveKit provides scalable, multi-user conferencing based on WebRTC. It allows to build real-time video audio data capabilities | [Demo code](./livekit/README.md) |
| **Llama Stack** | LLM frameworks  | Llama Stack standardizes the core building blocks that simplify AI application development. It codifies best practices across the Llama ecosystem. | [Demo code](./llama_stack/README.md) |
| **LM Evaluation Harness** | Eval and observability  | LM Evaluation Harness is a unified evaluation framework developed by EleutherAI for testing generative language models on a large number of different evaluation tasks. | [Demo Code](./lm_eval_harness/) |
| **MCP Server** | Tool and Browser Use | The Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. | [Demo code](./mcp) |
| **Mem0** | Vector DB and search | Mem0 enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. | [Demo code](./mem0) |
| **Milvus** | Vector DB and search | Milvus is an open-source vector database from Milvus and can easily enable RAG applications. | [Demo code](./milvus) |
| **n8n** | Low-code platforms | n8n is a low-code workflow automation framework. | [Demo code](./n8n) |
| **Open WebUI** | Self-hosted LLM interfaces | Open WebUI is an extensible UI you can host yourself to route prompts to SambaNova’s OpenAI-compatible endpoints while also unlocking optional Ollama, litellm, and local runners, complete with built-in RAG tools. | [Documentation](https://docs.openwebui.com/) |
| **Oumi** | LLM frameworks | Oumi is an open-source platform that streamlines the entire lifecycle of foundation models from data preparation and training to evaluation and deployment. | [Documentation](https://oumi.ai/docs/en/latest/api/oumi.inference.html#oumi.inference.SambanovaInferenceEngine) |
| **Pipecat** | LLM framework | Pipecat is an open source Python framework that handles the complex orchestration of AI services, network transport, audio processing, and multimodal interactions. | [Demo code](./pipecat_integration/README.md) |
| **Qwen Code CLI** | Coding assistants | Qwen Code CLI is a command-line tool for interacting with Alibaba’s Qwen and other OpenAI compatible models, designed to help developers explore, analyze, and optimize code directly from the terminal. | [Demo code](./qwen_code/README.md) |
| **Roo-Code** | Coding assistants | Roo Code is an AI-powered autonomous coding agent, that allows the utilization and creation of different agent roles to accelerate the development process. | [Documentation](https://docs.roocode.com/providers/sambanova) |
| **Semantic Kernel** | Agent building and orchestration | Semantic Kernel is an open-source development tool to build agents and integrate them with the latest AI models into your codebase.  | [Demo code](./semantic_kernel) |
| **Vercel** | LLM frameworks | Vercel is a platform for deploying and hosting web applications, which developers can use to easily manage their websites and serverless functions. | [Documentation](https://sdk.vercel.ai/providers/community-providers/sambanova) |
| **VS Code AI Toolkit** | Coding assistants | VS code AI toolkit is an extension within the IDE to develop and optimize AI agents within the code editor. | [Documentation](https://docs.sambanova.ai/cloud/docs/integrations/vscode) |
| **Weave** | LLM frameworks | Weave is a platform that provides tools for training, fine-tuning, and deploying machine learning models. | [Demo Code](./weave/) |

## AI Starter kits

SambaNova AI Starter Kits are a collection of open-source examples and guides designed to facilitate the deployment of AI-driven use cases for both developers and enterprises. check the available kits [here](https://github.com/sambanova/ai-starter-kit)

## Official Documentation

- View more docuemnation about [SambaNova Cloud integrations](https://docs.sambanova.ai/cloud/docs/integrations).
- Visit [SambaNova Cloud docs](https://docs.sambanova.ai/cloud/docs/get-started/overview) for all documentation.

**Note:** These Integrations code samples are provided "as-is," and are not production-ready or supported code. Bugfix/support will be on a best-effort basis only. Code may use third-party open-source software. You are responsible for performing due diligence per your organization policies for use in your applications.
