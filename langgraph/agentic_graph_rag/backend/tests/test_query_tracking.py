"""
Test suite for query tracking system.
Tests both standard tools and cypher subgraph integration.

TEST COVERAGE:
==============

Standard Tools (6 tools total):
--------------------------------
1. search_patients - test_search_patients_tool
   - Tests: Patient name search functionality
   - Expected routing: Direct tool call (matches specific_patient_keywords)
   - Cypher tracked: Patient search with CONTAINS clause

2. get_patient_procedures - test_get_patient_procedures_tool
   - Tests: Retrieval of patient procedures
   - Expected routing: Direct tool call (patient-specific query)
   - Cypher tracked: Patient->Encounter->Procedure relationship

3. get_patient_medications - test_get_patient_medications_tool
   - Tests: Retrieval of patient medications/drugs
   - Expected routing: Direct tool call (patient-specific query)
   - Cypher tracked: Patient->Encounter->Drug relationship

4. get_patient_conditions - test_get_patient_conditions_tool
   - Tests: Retrieval of patient conditions/diagnoses
   - Expected routing: Direct tool call (patient-specific query)
   - Cypher tracked: Patient->Encounter->Diagnosis relationship
   - Note: May use HAS_DIAGNOSIS instead of HAS_CONDITION based on actual schema

5. get_patient_encounters - test_get_patient_encounters_tool
   - Tests: Retrieval of patient encounters/visits
   - Expected routing: Direct tool call (patient-specific query)
   - Cypher tracked: Patient->Encounter relationship with labels

6. get_database_schema - test_get_database_schema_tool
   - Tests: Schema information retrieval
   - Expected routing: Direct tool call (matches "database schema" keyword)
   - Cypher tracked: None (returns static schema description)

Cypher Subgraph (2 tests):
---------------------------
7. cypher_subgraph (simple analytics) - test_cypher_subgraph_simple_analytics
   - Tests: Simple count aggregation
   - Expected routing: Cypher subgraph (no specific patient keywords)
   - Cypher tracked: Generated by DeepSeek model, executed by subgraph
   - Query type: COUNT aggregation

8. cypher_subgraph (complex analytics) - test_cypher_subgraph_complex_analytics
   - Tests: Complex aggregation with ordering and limiting
   - Expected routing: Cypher subgraph (analytics pattern)
   - Cypher tracked: Generated query with ORDER BY and LIMIT
   - Query type: Aggregation, grouping, and ranking

Response Quality Tests:
-----------------------
9. response_formatting - test_response_formatting_no_comprehensive_preamble
   - Tests: Summary agent response quality and directness
   - Expected routing: Cypher subgraph (analytics query)
   - Validates: NO "comprehensive" preambles, direct answers
   - Expected content: "Leonor133 Dicki44" and "$4,570,388.07"

QUERY TRACKING VERIFICATION:
============================
Each test verifies:
- Query is captured in executed_queries list
- Query source matches expected tool/subgraph
- Query contains valid Cypher syntax
- Parameters are tracked (for parameterized queries)
- Timestamp is recorded
- Total query count increases correctly

ROUTING LOGIC VERIFICATION:
===========================
- Tests 1-6: Should use standard tools (specific patient patterns)
- Tests 7-8: Should route to cypher subgraph (analytics patterns)
- Routing keywords tested:
  * "patient named" → standard tools
  * "database schema" → standard tools
  * "How many" → cypher subgraph
  * "most frequently" → cypher subgraph
"""
import sys
sys.path.append('..')

import pytest
from agent import create_agent, query_agent
import os
from dotenv import load_dotenv
from pathlib import Path

# Load environment variables from backend/.env
# Get the backend directory (parent of tests directory)
backend_dir = Path(__file__).parent.parent
env_path = backend_dir / '.env'
load_dotenv(env_path)


@pytest.fixture(scope="function")
def agent():
    """Create a fresh agent for each test to ensure complete isolation."""
    # Create a completely new agent instance for each test
    # This ensures no state accumulation between tests
    return create_agent()


@pytest.fixture(scope="function")
def conversation_state():
    """Initialize fresh conversation history and executed queries for each test."""
    # Return a new dict with fresh empty lists for each test
    # This ensures no conversation history or query accumulation between tests
    return {
        "history": [],
        "queries": []
    }

@pytest.mark.timeout(60)
def test_search_patients_tool(agent, conversation_state):
    """
    Test 1: search_patients tool
    Coverage: Standard tool for patient search
    Expected: Query with CONTAINS clause for name matching
    Routing: Matches "patient named" keyword → standard tools
    """
    print("\n" + "-" * 60)
    print("Test 1: search_patients Tool")
    print("-" * 60)

    question = "Search for patients named John"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 300 chars):")
    print(response[:300] + "..." if len(response) > 300 else response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    latest = conversation_state["queries"][-1]
    print(f"  Source: {latest['source']}")
    print(f"  Cypher: {latest['query'][:100]}...")

    assert "CONTAINS" in latest["query"].upper() or "search_patients" in latest["source"].lower()


@pytest.mark.timeout(60)
def test_get_patient_procedures_tool(agent, conversation_state):
    """
    Test 2: get_patient_procedures tool
    Coverage: Patient->Encounter->Procedure relationship
    Expected: Query traversing HAS_ENCOUNTER and HAS_PROCEDURE relationships
    Routing: Patient-specific query → standard tools
    """
    print("\n" + "-" * 60)
    print("Test 2: get_patient_procedures Tool")
    print("-" * 60)

    question = "What procedures has patient Ethan766 had?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (FULL):")
    print(response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    latest = conversation_state["queries"][-1]
    print(f"\nLatest Query:")
    print(f"  Source: {latest['source']}")
    print(f"  Cypher: {latest['query'][:150]}...")


@pytest.mark.timeout(60)
def test_get_patient_medications_tool(agent, conversation_state):
    """
    Test 3: get_patient_medications tool
    Coverage: Patient->Encounter->Drug relationship
    Expected: Query traversing HAS_ENCOUNTER and HAS_DRUG relationships
    Routing: Patient-specific query → standard tools
    """
    print("\n" + "-" * 60)
    print("Test 3: get_patient_medications Tool")
    print("-" * 60)

    question = "What medications is Ethan766 taking?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (FULL):")
    print(response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    # Assert that response should not mention "recent 30" when less than 30 results returned
    assert "recent 30" not in response.lower(), \
        "Response should not mention 'recent 30' when fewer than 30 results were returned"

    latest = conversation_state["queries"][-1]
    print(f"\nLatest Query:")
    print(f"  Source: {latest['source']}")


@pytest.mark.timeout(60)
def test_get_patient_conditions_tool(agent, conversation_state):
    """
    Test 4: get_patient_conditions tool
    Coverage: Patient->Encounter->Diagnosis relationship
    Expected: Query traversing HAS_ENCOUNTER and HAS_DIAGNOSIS relationships
    Routing: Patient-specific query → standard tools
    Note: Schema uses HAS_DIAGNOSIS, not HAS_CONDITION
    """
    print("\n" + "-" * 60)
    print("Test 4: get_patient_conditions Tool (Note: may use diagnoses instead)")
    print("-" * 60)

    question = "What diagnoses does Ethan766 have?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (FULL):")
    print(response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    # Assert that response should not mention "top 30" when less than 30 results returned
    assert "top 30" not in response.lower(), \
        "Response should not mention 'top 30' when fewer than 30 results were returned"


@pytest.mark.timeout(60)
def test_get_patient_encounters_tool(agent, conversation_state):
    """
    Test 5: get_patient_encounters tool
    Coverage: Patient->Encounter relationship with encounter labels
    Expected: Query returning encounters with multi-label support (Emergency, Wellness, etc.)
    Routing: Patient-specific query → standard tools
    """
    print("\n" + "-" * 60)
    print("Test 5: get_patient_encounters Tool")
    print("-" * 60)

    question = "Show me all encounters for Ethan766"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 400 chars):")
    print(response[:400] + "..." if len(response) > 400 else response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"


@pytest.mark.timeout(60)
def test_get_database_schema_tool(agent, conversation_state):
    """
    Test 6: get_database_schema tool
    Coverage: Schema information retrieval (static, no Cypher execution)
    Expected: No query tracked (returns static description)
    Routing: Matches "database schema" keyword → standard tools
    """
    print("\n" + "-" * 60)
    print("Test 6: get_database_schema Tool")
    print("-" * 60)

    question = "What is the database schema?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 300 chars):")
    print(response[:300] + "..." if len(response) > 300 else response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert response is not None and len(response) > 0, "No response received"


@pytest.mark.timeout(60)
def test_cypher_subgraph_simple_analytics(agent, conversation_state):
    """
    Test 7: Cypher subgraph - simple count
    Coverage: Cypher subgraph with COUNT aggregation
    Expected: LLM-generated query with COUNT(p) pattern
    Routing: "How many" keyword → cypher subgraph (catch-all for analytics)
    """
    print("\n" + "-" * 60)
    print("Test 7: Cypher Subgraph - Simple Analytics")
    print("-" * 60)

    question = "How many patients are in the database?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response:")
    print(response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    latest = conversation_state["queries"][-1]
    print(f"\nLatest Query:")
    print(f"  Source: {latest['source']}")
    print(f"  Cypher: {latest['query'][:150]}...")
    if latest.get('question'):
        print(f"  Original Question: {latest['question']}")


@pytest.mark.timeout(60)
def test_cypher_subgraph_complex_analytics(agent, conversation_state):
    """
    Test 8: Cypher subgraph - complex analytics
    Coverage: Cypher subgraph with complex aggregation, grouping, and ranking
    Expected: LLM-generated query with GROUP BY, ORDER BY, LIMIT
    Routing: "most frequently" keyword → cypher subgraph (analytics pattern)
    """
    print("\n" + "-" * 60)
    print("Test 8: Cypher Subgraph - Complex Analytics")
    print("-" * 60)

    question = "Which procedures were performed most frequently? Show top 10."
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 600 chars):")
    print(response[:600] + "..." if len(response) > 600 else response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    latest = conversation_state["queries"][-1]
    print(f"\nLatest Query:")
    print(f"  Source: {latest['source']}")
    print(f"  Cypher (first 200 chars): {latest['query'][:200]}...")


@pytest.mark.timeout(60)
def test_response_formatting_no_comprehensive_preamble(agent, conversation_state):
    """
    Test 9: Response formatting - No comprehensive preambles
    Coverage: Verify summary agent provides direct answers without verbose preambles
    Expected: Direct answer with patient name and amount, NO "comprehensive" phrase
    Routing: Analytics query → cypher subgraph

    This test ensures the summary agent:
    - Does NOT use "To provide a more comprehensive answer"
    - Contains expected data: "Leonor133 Dicki44" and "$4,570,388.07"
    - Formats single results as sentences, NOT bullet lists
    """
    print("\n" + "-" * 60)
    print("Test 9: Response Formatting - No Comprehensive Preamble")
    print("-" * 60)

    question = "Which patient has spent the most on treatments?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Full Response:")
    print("-" * 60)
    print(response)
    print("-" * 60)

    # Check that response contains expected content
    assert "Leonor133 Dicki44" in response, \
        "Response should contain patient name 'Leonor133 Dicki44'"

    assert "$4,570,388.07" in response, \
        "Response should contain amount '$4,570,388.07'"

    # Check that response does NOT contain the preamble phrase
    assert "To provide a more comprehensive answer" not in response, \
        "Response should NOT contain 'To provide a more comprehensive answer'"

    print("\n✓ Test passed: Response is direct and concise")
    print(f"✓ Contains patient name: Leonor133 Dicki44")
    print(f"✓ Contains amount: $4,570,388.07")
    print(f"✓ Does NOT contain comprehensive preamble")

    # Verify at least one query was executed
    assert len(conversation_state["queries"]) > 0, "No queries were executed"
    print(f"✓ Queries executed: {len(conversation_state['queries'])}")


@pytest.mark.timeout(60)
def test_validation_relevant_query(agent, conversation_state):
    """
    Test 10: Validation - Relevant Query
    Coverage: Validation node accepts medically-relevant queries
    Expected: Query passes validation and proceeds to agent
    Routing: validation → agent → tools
    """
    print("\n" + "-" * 60)
    print("Test 10: Validation - Relevant Medical Query")
    print("-" * 60)

    question = "What medications is patient Ethan766 taking?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 400 chars):")
    print(response[:400] + "..." if len(response) > 400 else response)

    # Should NOT be rejected
    assert "I am sorry - I can only answer questions that pertain to the Synthea medical records" not in response, \
        "Medically-relevant query should NOT be rejected by validation"

    # Should proceed to execute queries
    assert len(conversation_state["queries"]) > 0, "Relevant query should execute database queries"

    print("\n✓ Test passed: Relevant query accepted by validation")
    print(f"✓ Queries executed: {len(conversation_state['queries'])}")


@pytest.mark.timeout(60)
def test_validation_irrelevant_query_weather(agent, conversation_state):
    """
    Test 11: Validation - Irrelevant Query (Weather)
    Coverage: Validation node rejects non-medical queries
    Expected: Query is rejected with standard message
    Routing: validation → end (no agent/tools)
    """
    print("\n" + "-" * 60)
    print("Test 11: Validation - Irrelevant Query (Weather)")
    print("-" * 60)

    question = "What's the weather like today?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response:")
    print(response)

    # Should be rejected with exact message
    assert "I am sorry - I can only answer questions that pertain to the Synthea medical records" in response, \
        "Irrelevant query should be rejected with standard message"

    # Should NOT execute any queries
    assert len(conversation_state["queries"]) == 0, \
        "Rejected query should NOT execute any database queries"

    print("\n✓ Test passed: Irrelevant query rejected by validation")
    print(f"✓ No queries executed (as expected): {len(conversation_state['queries'])}")


@pytest.mark.timeout(60)
def test_validation_irrelevant_query_general_knowledge(agent, conversation_state):
    """
    Test 12: Validation - Irrelevant Query (General Knowledge)
    Coverage: Validation node rejects general knowledge questions
    Expected: Query is rejected with standard message
    Routing: validation → end (no agent/tools)
    """
    print("\n" + "-" * 60)
    print("Test 12: Validation - Irrelevant Query (General Knowledge)")
    print("-" * 60)

    question = "Who is the president of the United States?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response:")
    print(response)

    # Should be rejected with exact message
    assert "I am sorry - I can only answer questions that pertain to the Synthea medical records" in response, \
        "General knowledge query should be rejected with standard message"

    # Should NOT execute any queries
    assert len(conversation_state["queries"]) == 0, \
        "Rejected query should NOT execute any database queries"

    print("\n✓ Test passed: General knowledge query rejected by validation")
    print(f"✓ No queries executed (as expected): {len(conversation_state['queries'])}")


@pytest.mark.timeout(60)
def test_validation_edge_case_database_schema_query(agent, conversation_state):
    """
    Test 13: Validation - Edge Case (Database Schema Query)
    Coverage: Validation accepts queries about the database itself
    Expected: Query passes validation (database schema is relevant)
    Routing: validation → agent → tools
    """
    print("\n" + "-" * 60)
    print("Test 13: Validation - Edge Case (Database Schema)")
    print("-" * 60)

    question = "What is the database schema?"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (first 400 chars):")
    print(response[:400] + "..." if len(response) > 400 else response)

    # Should NOT be rejected
    assert "I am sorry - I can only answer questions that pertain to the Synthea medical records" not in response, \
        "Database schema query should NOT be rejected by validation"

    # Should contain schema information
    assert "Patient" in response or "Encounter" in response or "schema" in response.lower(), \
        "Response should contain schema information"

    print("\n✓ Test passed: Database schema query accepted by validation")
    print(f"✓ Response contains schema information")


@pytest.mark.timeout(120)
def test_find_similar_patients_tool(agent, conversation_state):
    """
    Test 14: find_similar_patients tool
    Coverage: Patient similarity using KNN embeddings
    Expected: Query returning similar patients with similarity scores and medical stats
    Routing: Patient similarity query → find_similar_patients tool

    This test verifies:
    - Tool is invoked for similarity queries
    - Returns list of similar patients with scores
    - Includes medical stats (age, encounters, procedures, medications, expenses)
    - Uses KNN_SIMILARITY relationship (Test 1 format from test_similarity_query.py)
    """
    print("\n" + "-" * 60)
    print("Test 14: find_similar_patients Tool")
    print("-" * 60)

    question = "Find the most similar patients to Joi660 Barrows492"
    print(f"Question: {question}\n")

    response, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question, conversation_state["history"], conversation_state["queries"]
    )

    print("Response (FULL):")
    print(response)
    print(f"\n✓ Queries executed: {len(conversation_state['queries'])}")

    # Verify at least one query was executed
    assert len(conversation_state["queries"]) > 0, "No queries were executed"

    # Verify the query source is find_similar_patients
    latest = conversation_state["queries"][-1]
    print(f"\nLatest Query:")
    print(f"  Source: {latest['source']}")
    print(f"  Tool Args: {latest.get('tool_args', {})}")

    assert latest["source"] == "find_similar_patients", \
        f"Expected source 'find_similar_patients', got '{latest['source']}'"

    # Verify response contains expected elements
    # Should have similarity scores, patient names, and medical stats
    if "No similar patients found" not in response:
        # Check for key elements in the response
        assert "similar" in response.lower(), \
            "Response should mention similar patients"

        # Check for at least one of the medical statistics fields
        has_medical_stats = any(keyword in response.lower() for keyword in
            ["similarity score", "age", "encounters", "procedures", "medications", "expenses"])
        assert has_medical_stats, \
            "Response should include medical statistics (similarity score, age, encounters, etc.)"

        print("\n✓ Test passed: find_similar_patients tool executed successfully")
        print("✓ Response contains similarity scores and medical statistics")
    else:
        print("\n✓ Test passed: Tool executed (patient not found or no similarity data)")
        print("  Note: This may indicate embeddings need to be generated")


@pytest.mark.timeout(180)
def test_multi_turn_conversation(agent, conversation_state):
    """
    Test 15: Multi-turn conversation with context preservation
    Coverage: Multi-turn conversation maintaining context across questions
    Expected: Agent correctly uses pronouns and context from previous questions
    Routing:
    - Turn 1: Analytics query → cypher subgraph
    - Turn 2: Pronoun reference ("he") → should resolve to patient from Turn 1
    - Turn 3: Similarity query ("him") → should use find_similar_patients with patient from Turn 1

    This test verifies:
    - Conversation history is maintained between turns
    - Agent resolves pronoun references (he, him) correctly
    - Context from earlier questions is used in later queries
    - Multiple different tools/subgraphs can be used in sequence
    """
    print("\n" + "=" * 60)
    print("Test 15: Multi-turn Conversation")
    print("=" * 60)

    # Turn 1: Which patient has spent the most on treatments?
    print("\n" + "-" * 60)
    print("Turn 1: Initial analytics query")
    print("-" * 60)
    question1 = "Which patient has spent the most on treatments?"
    print(f"Question: {question1}\n")

    response1, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question1, conversation_state["history"], conversation_state["queries"]
    )

    print("Response 1:")
    print(response1)
    print(f"\n✓ Queries executed after turn 1: {len(conversation_state['queries'])}")

    # Verify first response contains a patient name and expense amount
    # (Don't hardcode patient name as it may vary with database)
    assert len(conversation_state["queries"]) > 0, "No queries were executed"
    assert any(keyword in response1.lower() for keyword in ["spent", "expense", "treatment", "cost"]), \
        "First response should mention treatment expenses"

    # Extract patient name for validation in subsequent turns
    # Response should contain a name pattern (FirstName LastName)
    import re
    patient_match = re.search(r'([A-Z][a-z]+\d*\s+[A-Z][a-z]+\d*)', response1)
    assert patient_match, "First response should contain a patient name"
    patient_name = patient_match.group(1)
    print(f"✓ Identified patient: {patient_name}")

    # Turn 2: how old is he?
    print("\n" + "-" * 60)
    print("Turn 2: Pronoun reference query (he)")
    print("-" * 60)
    question2 = "how old is he?"
    print(f"Question: {question2}\n")

    response2, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question2, conversation_state["history"], conversation_state["queries"]
    )

    print("Response 2:")
    print(response2)
    print(f"\n✓ Queries executed after turn 2: {len(conversation_state['queries'])}")

    # Verify second response resolves "he" to the patient from turn 1
    # Should contain age information
    assert any(keyword in response2.lower() for keyword in ["age", "year", "old", "born"]), \
        "Second response should contain age information"

    # Turn 3: find patients similar to him
    print("\n" + "-" * 60)
    print("Turn 3: Similarity query with pronoun reference (him)")
    print("-" * 60)
    question3 = "find patients similar to him"
    print(f"Question: {question3}\n")

    response3, conversation_state["history"], conversation_state["queries"], _ = query_agent(
        agent, question3, conversation_state["history"], conversation_state["queries"]
    )

    print("Response 3:")
    print(response3)
    print(f"\n✓ Queries executed after turn 3: {len(conversation_state['queries'])}")

    # Verify third response uses similarity search
    # Should mention similar patients
    assert "similar" in response3.lower(), \
        "Third response should mention similar patients"

    # Print summary
    print("\n" + "=" * 60)
    print("Multi-turn Conversation Summary")
    print("=" * 60)
    print(f"✓ Total queries executed: {len(conversation_state['queries'])}")
    print(f"✓ Conversation history entries: {len(conversation_state['history'])}")
    print("✓ Turn 1: Identified patient with highest treatment costs")
    print("✓ Turn 2: Resolved pronoun 'he' and returned age information")
    print("✓ Turn 3: Resolved pronoun 'him' and found similar patients")
    print("=" * 60)
