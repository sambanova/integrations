{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e178dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example_server.py\n",
    "from datetime import datetime\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP('Test')\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return f'current_time: {datetime.now().isoformat()}'\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def tavily_search(search_query: str) -> str:\n",
    "    \"\"\"Performs a web search using the Tavily API.\"\"\"\n",
    "    return f\"Results for '{search_query}' from Tavily search.\"\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_weather(city: str, metric: str = 'celsius') -> str:\n",
    "    \"\"\"Get weather info for a city.\"\"\"\n",
    "    return f'It is 23 {metric} in {city}'\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_current_weather(location: str, unit: str = 'celsius', user: dict = None) -> dict:\n",
    "    \"\"\"Get the current weather in a location, customized by user details.\"\"\"\n",
    "    if not user or 'name' not in user:\n",
    "        raise ValueError(\"User details with 'name' field are required.\")\n",
    "\n",
    "    return {'location': location, 'unit': unit, 'user': user, 'weather': f'Sunny, 22 degrees {unit}'}\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_user_info(user_id: int, special: str = 'none') -> dict:\n",
    "    \"\"\"Retrieve user details by ID.\"\"\"\n",
    "    return {'user_id': user_id, 'special': special, 'info': {'name': 'John Doe', 'email': 'john.doe@example.com'}}\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def yahoo_finance_search(symbol: str) -> dict:\n",
    "    \"\"\"Get current stock information for a given symbol.\"\"\"\n",
    "    return {'symbol': symbol, 'price': '123.45', 'currency': 'USD'}\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def exa_news_search(query: str, answer: bool = False) -> dict:\n",
    "    \"\"\"Search news via Exa API.\"\"\"\n",
    "    return {'query': query, 'answer_required': answer, 'results': ['News headline 1', 'News headline 2']}\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def my_adder_tool(a: int, b: int) -> str:\n",
    "    \"\"\"Takes two integers and returns their sum.\"\"\"\n",
    "    return f'sum: {a + b}'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834c7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64232170",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='https://api.sambanova.ai/v1/',\n",
    "    api_key='SAMBANOVA-API-KEY',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d89fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_calling(\n",
    "    messages: List[Dict[str, Any]],\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    tools: List[Dict[str, Any]] = None,\n",
    "    tool_choice: str = 'auto',\n",
    "    parallel_tool_calls: bool = False,\n",
    "    response_format: Dict[str, Any] = None,\n",
    "    stream: bool = False,\n",
    ") -> Any:\n",
    "    if tools is not None:\n",
    "        tools_args = {'tools': tools, 'tool_choice': tool_choice, 'parallel_tool_calls': parallel_tool_calls}\n",
    "    else:\n",
    "        tools_args = {}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model, messages=messages, stream=stream, response_format=response_format, **tools_args\n",
    "        )\n",
    "        if stream:\n",
    "            for chunk in completion:\n",
    "                results.append(chunk.choices)\n",
    "        else:\n",
    "            if completion and hasattr(completion, 'error'):\n",
    "                results = f'Error: {completion.error}'\n",
    "            else:\n",
    "                results = completion.choices[0].message\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def mcp_to_json_schema(mcp_tool: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    json_schema = {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': mcp_tool['name'],\n",
    "            'description': mcp_tool['description'],\n",
    "            'parameters': {'type': 'object', 'properties': {}},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if 'inputSchema' in mcp_tool and mcp_tool['inputSchema']:\n",
    "        input_schema = mcp_tool['inputSchema']\n",
    "        if 'properties' in input_schema:\n",
    "            for param_name, param_details in input_schema['properties'].items():\n",
    "                json_schema['function']['parameters']['properties'][param_name] = {\n",
    "                    'type': param_details['type'],\n",
    "                    'description': param_details.get('description', ''),\n",
    "                }\n",
    "\n",
    "                if 'required' in input_schema and param_name in input_schema['required']:\n",
    "                    if 'required' not in json_schema['function']['parameters']:\n",
    "                        json_schema['function']['parameters']['required'] = []\n",
    "                    json_schema['function']['parameters']['required'].append(param_name)\n",
    "\n",
    "                if 'default' in param_details:\n",
    "                    json_schema['function']['parameters']['properties'][param_name]['default'] = param_details[\n",
    "                        'default'\n",
    "                    ]\n",
    "\n",
    "    if '$defs' in mcp_tool:\n",
    "        json_schema['function']['parameters']['$defs'] = mcp_tool['$defs']\n",
    "\n",
    "    return json_schema\n",
    "\n",
    "\n",
    "async def mcp_client(\n",
    "    available_tools: List[str],\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, Any]],\n",
    "    stream: bool,\n",
    "    server_params: Dict[str, Any],\n",
    ") -> Any:\n",
    "    server_params = StdioServerParameters(**server_params)\n",
    "\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            tools = await session.list_tools()\n",
    "\n",
    "            tools_schemas = []\n",
    "\n",
    "            for tool in tools.tools:\n",
    "                if tool.name in available_tools:\n",
    "                    tool_dict = json.loads(tool.model_dump_json())\n",
    "                    final_tool = mcp_to_json_schema(tool_dict)\n",
    "                    tools_schemas.append(final_tool)\n",
    "            response = function_calling(messages, client, model, tools_schemas, stream=stream)\n",
    "\n",
    "            tool_result = await session.call_tool(\n",
    "                response.tool_calls[0].function.name, arguments=json.loads(response.tool_calls[0].function.arguments)\n",
    "            )\n",
    "\n",
    "            messages.append(\n",
    "                {'role': 'tool', 'tool_call_id': response.tool_calls[0].id, 'content': str(tool_result.content[0].text)}\n",
    "            )\n",
    "\n",
    "            final_response = function_calling(messages, client, model)\n",
    "\n",
    "            return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca78e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_server_params = {'command': 'python', 'args': ['example_server.py'], 'env': None}\n",
    "\n",
    "path = '/Users/user/Downloads'\n",
    "\n",
    "server_params = {'command': 'npx', 'args': ['-y', '@modelcontextprotocol/server-filesystem', path], 'env': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = (\n",
    "    [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant. uUse tools available to answer user questions',\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': \"I am based in Cambridge and need to catch a train soon. What's the current time?\",\n",
    "        },\n",
    "    ],\n",
    "    ['get_current_time', 'tavily_search'],\n",
    ")\n",
    "\n",
    "example_2 = (\n",
    "    [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant. uUse tools available to answer user questions',\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'List all the file in {path} folder',\n",
    "        },\n",
    "    ],\n",
    "    ['list_directory'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f6e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await mcp_client(example[1], client, 'Meta-Llama-3.3-70B-Instruct', example[0], False, custom_server_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e1e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The current time is 12:54:51. Please check the latest train schedule to ensure you catch your train on time.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8225100",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = await mcp_client(example_2[1], client, 'Meta-Llama-3.3-70B-Instruct', example_2[0], False, server_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c6b89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"It seems like you're trying to list all the files in the `/Users/luiss/Downloads` folder. The output you provided shows a mix of files and directories. Here's a breakdown:\\n\\n**Files:**\\n\\n1. `.DS_Store`\\n2. `.localized`\\n\\n**Directories:**\\n\\n1. `audio_test`\\n2. `custom_data`\\n3. `github`\\n4. `images_test`\\n5. `kubernetes`\\n6. `models`\\n7. `postman`\\n\\nPlease note that the output might not be exhaustive, as the command or method used to generate the list might have limitations or filters applied. If you need to list all files and subdirectories recursively, you can use a command like `ls -R /Users/luiss/Downloads` in a terminal or command prompt.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
