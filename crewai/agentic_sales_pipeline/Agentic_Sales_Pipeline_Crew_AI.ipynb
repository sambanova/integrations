{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e744665e-7420-433f-8463-a674b66492d5",
   "metadata": {},
   "source": [
    "# **Agentic Sales Pipeline SambaNova & CrewAI**\n",
    "\n",
    "This tutorial and companion notebook demonstrate how to create an **Agentic Sales Pipeline** using **CrewAI** integrated with **SambaNova's Meta-Llama 3.1 70B Instruct** model. The workflow automates lead qualification, scoring, and personalized email engagement by orchestrating agents that collect data, analyze cultural fit, and draft emails. The pipeline showcases modular design, high inference performance, and the ability to visualize and execute multi-step AI workflows efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6203ca4",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "In the world of sales, time is money. Manually qualifying leads, scoring them, and drafting follow-up emails can be tedious and inefficient. **Agentic AI workflows** powered by **CrewAI** and **SambaNova’s LLMs** can automate these tasks. This guide will walk you through setting up an **Agentic Sales Pipeline** to qualify, score, and engage leads.\n",
    "\n",
    "We’ll break down each step, explaining how **CrewAI’s components**—**Agents**, **Tasks**, **Crews**, and **Flows**—work together to accomplish these goals.\n",
    "\n",
    "## **Understanding the Core Components of CrewAI**\n",
    "\n",
    "Before we dive into the code, let’s explore the key building blocks of CrewAI:\n",
    "\n",
    "**The LLM Class:** Encapsulates a **Large Language Model** used by agents to perform tasks. In this pipeline, we use **SambaNova’s Meta-Llama 3.1 70B Instruct** model, known for its high speed and power efficiency.\n",
    "\n",
    "**The Task Class:** Defines **specific objectives** for agents. Each task contains a Goal (what the agent should accomplish), an Agent (the AI worker assigned to the task) and Tools (optional utilities, like a web search, to assist the agent). Tasks are modular and can be easily modified or reused.\n",
    "\n",
    "**The Crew Class:** Brings agents together to work collaboratively, managing task execution, communication between agents, and providing debugging information.\n",
    "\n",
    "With these components in mind, let’s set up our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ff40f-0146-47f9-84db-36997a267b8d",
   "metadata": {},
   "source": [
    "## **1\\. Setting Up the Environment** \n",
    "\n",
    "First, make sure to install the needed dependencies from the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20723f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Requirements\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3bd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import asyncio\n",
    "import getpass\n",
    "import nest_asyncio\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from crewai import  Agent, Crew, Flow, LLM, Task\n",
    "from crewai.flow.flow import listen, start, and_, or_, router\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool\n",
    "from dotenv import load_dotenv\n",
    "from litellm import cost_per_token\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d759f",
   "metadata": {},
   "source": [
    "Second, we’ll need to install dependencies and configure API keys. We need the following API keys:\n",
    "\n",
    "Get your Sambanova API Key Here https://cloud.sambanova.ai/\n",
    "\n",
    "Get your Serper API Key Here https://serper.dev/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8535d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API keys and base URL if not already configured in environment\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"SAMBANOVA_API_KEY\" not in os.environ:\n",
    "    os.environ[\"SAMBANOVA_API_KEY\"] = getpass.getpass(\"insert your SambaNova API Key\") \n",
    "    \n",
    "if \"SAMBANOVA_BASE_URL\" not in os.environ:\n",
    "    os.environ[\"SAMBANOVA_BASE_URL\"] = \"https://api.sambanova.ai/v1\"\n",
    "    \n",
    "if \"SERPER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"SERPER_API_KEY\"] = getpass.getpass(\"insert your Serper API Key\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0f3b5",
   "metadata": {},
   "source": [
    "## **2\\. Initializing the LLM** \n",
    "\n",
    "To make LLM calls, we’ll need to set up the SambaNova LLM for agents to use in their tasks. We’ll initialize the **Meta-Llama 3.1 70B Instruct** model, which agents will use to process and generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13af297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Sambanova LLM\n",
    "model = 'sambanova/Meta-Llama-3.1-70B-Instruct'\n",
    "llm = LLM(\n",
    "    model=model, \n",
    "    base_url=os.getenv(\"SAMBANOVA_BASE_URL\"),\n",
    "    api_key=os.getenv(\"SAMBANOVA_API_KEY\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2797f-c0de-451e-a73b-bff04f981172",
   "metadata": {},
   "source": [
    "## **3\\. Loading Agent and Task Configurations** \n",
    "\n",
    "Next, we’ll need to define some agents and tasks to deliver our use case. CrewAI promotes modularity by allowing you to define agents and tasks in YAML files. This makes it easy to update roles and objectives without changing the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c943fa8-fda9-495c-9225-a841af833fea",
   "metadata": {
    "height": 351
   },
   "outputs": [],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'lead_agents': 'config/lead_qualification_agents.yaml',\n",
    "    'lead_tasks': 'config/lead_qualification_tasks.yaml',\n",
    "    'email_agents': 'config/email_engagement_agents.yaml',\n",
    "    'email_tasks': 'config/email_engagement_tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "lead_agents_config = configs['lead_agents']\n",
    "lead_tasks_config = configs['lead_tasks']\n",
    "email_agents_config = configs['email_agents']\n",
    "email_tasks_config = configs['email_tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25d7e2-143d-4223-b770-75c5dcaa257e",
   "metadata": {},
   "source": [
    "### Create Pydantic Models for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792a5ecb-fbc3-43e5-a5aa-06882d9f3765",
   "metadata": {
    "height": 453
   },
   "outputs": [],
   "source": [
    "class LeadPersonalInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"The full name of the lead.\")\n",
    "    job_title: str = Field(..., description=\"The job title of the lead.\")\n",
    "    role_relevance: int = Field(..., ge=0, le=10, description=\"A score representing how relevant the lead's role is to the decision-making process (0-10).\")\n",
    "    professional_background: Optional[str] = Field(..., description=\"A brief description of the lead's professional background.\")\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    company_name: str = Field(..., description=\"The name of the company the lead works for.\")\n",
    "    industry: str = Field(..., description=\"The industry in which the company operates.\")\n",
    "    company_size: int = Field(..., description=\"The size of the company in terms of employee count.\")\n",
    "    revenue: Optional[float] = Field(None, description=\"The annual revenue of the company, if available.\")\n",
    "    market_presence: int = Field(..., ge=0, le=10, description=\"A score representing the company's market presence (0-10).\")\n",
    "\n",
    "class LeadScore(BaseModel):\n",
    "    score: int = Field(..., ge=0, le=100, description=\"The final score assigned to the lead (0-100).\")\n",
    "    scoring_criteria: List[str] = Field(..., description=\"The criteria used to determine the lead's score.\")\n",
    "    validation_notes: Optional[str] = Field(None, description=\"Any notes regarding the validation of the lead score.\")\n",
    "\n",
    "class LeadScoringResult(BaseModel):\n",
    "    personal_info: LeadPersonalInfo = Field(..., description=\"Personal information about the lead.\")\n",
    "    company_info: CompanyInfo = Field(..., description=\"Information about the lead's company.\")\n",
    "    lead_score: LeadScore = Field(..., description=\"The calculated score and related information for the lead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd8c33-7009-4794-96b7-9a59c8669083",
   "metadata": {},
   "source": [
    "## **4\\. Creating Agents** \n",
    "\n",
    "Task: Define agents responsible for lead qualification and scoring.\n",
    "\n",
    "Agents are the AI workers that perform tasks. We’ll define three agents:\n",
    "\n",
    "1. **Lead Data Agent**: Collects lead information using search and scraping tools.  \n",
    "2. **Cultural Fit Agent**: Assesses if the lead aligns with company values.  \n",
    "3. **Scoring Validation Agent**: Validates and scores the lead.\n",
    "\n",
    "For each agent, we’ll also define:\n",
    "\n",
    "* **Tools**: Agents use **Serper** for search and **ScrapeWebsiteTool** for web scraping.  \n",
    "* **LLM**: Each agent uses the **Meta-Llama 3.1** model to process and generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e0ba2e-a86a-4a20-ab38-62eb89abdf57",
   "metadata": {
    "height": 844
   },
   "outputs": [],
   "source": [
    "# Creating Agents\n",
    "lead_data_agent = Agent(\n",
    "  config=lead_agents_config['lead_data_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "cultural_fit_agent = Agent(\n",
    "  config=lead_agents_config['cultural_fit_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "scoring_validation_agent = Agent(\n",
    "  config=lead_agents_config['scoring_validation_agent'],\n",
    "  tools=[SerperDevTool(), ScrapeWebsiteTool()],\n",
    "  llm=llm\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596d1c5",
   "metadata": {},
   "source": [
    "## **5\\. Defining Tasks** \n",
    "\n",
    "Next, we’ll need to create the tasks that agents will execute. Each task specifies what the agent needs to accomplish. For example:\n",
    "\n",
    "* **Lead Data Collection**: Collects basic information about leads.  \n",
    "* **Cultural Fit Analysis**: Analyzes lead fit.  \n",
    "* **Lead Scoring**: Scores and validates leads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a96a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tasks\n",
    "lead_data_task = Task(\n",
    "  config=lead_tasks_config['lead_data_collection'],\n",
    "  agent=lead_data_agent\n",
    ")\n",
    "\n",
    "cultural_fit_task = Task(\n",
    "  config=lead_tasks_config['cultural_fit_analysis'],\n",
    "  agent=cultural_fit_agent\n",
    ")\n",
    "\n",
    "scoring_validation_task = Task(\n",
    "  config=lead_tasks_config['lead_scoring_and_validation'],\n",
    "  agent=scoring_validation_agent,\n",
    "  context=[lead_data_task, cultural_fit_task],\n",
    "  output_pydantic=LeadScoringResult\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffabd2",
   "metadata": {},
   "source": [
    "## **6\\. Creating the Crew** \n",
    "\n",
    "Next, we’ll combine agents and tasks into a **Crew** to orchestrate the workflow. The **Crew** ensures tasks are executed in order and agents collaborate seamlessly, while verbose logging helps track progress and debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d51a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Crew\n",
    "lead_scoring_crew = Crew(\n",
    "  agents=[\n",
    "    lead_data_agent,\n",
    "    cultural_fit_agent,\n",
    "    scoring_validation_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    lead_data_task,\n",
    "    cultural_fit_task,\n",
    "    scoring_validation_task\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cec8e2-8aee-4abd-84c6-cde645f16e12",
   "metadata": {},
   "source": [
    "### Repeat Steps 4-6 for Email Engagement Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0e4d3-a150-4354-8deb-59c1758026fe",
   "metadata": {
    "height": 572
   },
   "outputs": [],
   "source": [
    "# Creating Agents\n",
    "email_content_specialist = Agent(\n",
    "  config=email_agents_config['email_content_specialist'],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "engagement_strategist = Agent(\n",
    "  config=email_agents_config['engagement_strategist'],\n",
    "  llm=llm\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "email_drafting = Task(\n",
    "  config=email_tasks_config['email_drafting'],\n",
    "  agent=email_content_specialist\n",
    ")\n",
    "\n",
    "engagement_optimization = Task(\n",
    "  config=email_tasks_config['engagement_optimization'],\n",
    "  agent=engagement_strategist\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "email_writing_crew = Crew(\n",
    "  agents=[\n",
    "    email_content_specialist,\n",
    "    engagement_strategist\n",
    "  ],\n",
    "  tasks=[\n",
    "    email_drafting,\n",
    "    engagement_optimization\n",
    "  ],\n",
    "  verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c235e8-9efd-4496-88fd-aa32b4744fb5",
   "metadata": {},
   "source": [
    "## **7\\. Creating the Sales Pipeline Flow** \n",
    "\n",
    "Task: Automate the sales pipeline process using a CrewAI Flow.\n",
    "\n",
    "In this step, we'll define a **Flow** that orchestrates the end-to-end sales process. The Flow will:\n",
    "\n",
    "1. **Fetch Leads**: Retrieve potential leads (mock data).  \n",
    "2. **Score Leads**: Run the lead scoring Crew to qualify and score the leads.  \n",
    "3. **Store Scores**: Save the lead scores (simulated).  \n",
    "4. **Filter High-Quality Leads**: Identify leads with scores above a threshold.  \n",
    "5. **Draft and Send Emails**: Generate personalized emails for high-quality leads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6976784-c70c-4ec8-882a-12b1250f4354",
   "metadata": {
    "height": 827
   },
   "outputs": [],
   "source": [
    "class SalesPipeline(Flow):\n",
    "    @start()\n",
    "    def fetch_leads(self):\n",
    "        # Pull our leads from the database\n",
    "        leads = [\n",
    "            {\n",
    "                \"lead_data\": {\n",
    "                    \"name\": \"Kwasi Ankomah\",\n",
    "                    \"job_title\": \"Architect\",\n",
    "                    \"company\": \"SambaNova\",\n",
    "                    \"email\": \"kwasi@samaba.com\",\n",
    "                    \"use_case\": \"Using AI Agents to do better data enrichment.\"\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "        return leads\n",
    "\n",
    "    @listen(fetch_leads)\n",
    "    def score_leads(self, leads):\n",
    "        scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "        self.state[\"score_crews_results\"] = scores\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def store_leads_score(self, scores):\n",
    "        # Here we would store the scores in the database\n",
    "        return scores\n",
    "\n",
    "    @listen(score_leads)\n",
    "    def filter_leads(self, scores):\n",
    "        return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "    @listen(filter_leads)\n",
    "    def write_email(self, leads):\n",
    "        scored_leads = [lead.to_dict() for lead in leads]\n",
    "        emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "        return emails\n",
    "\n",
    "    @listen(write_email)\n",
    "    def send_email(self, emails):\n",
    "        # Here we would send the emails to the leads\n",
    "        return emails\n",
    "\n",
    "flow = SalesPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1d640-12d2-4dbd-8095-7fe47dbd729c",
   "metadata": {},
   "source": [
    "## **8\\. Visualizing the Flow** \n",
    "\n",
    "CrewAI allows you to generate a visual representation of your Flow, which is useful for debugging and documentation. This will generate a diagram showing the sequence of steps in the sales pipeline from lead fetching to sending emails (simulated).\n",
    "* Note that Jupyter Notebooks is the preferred system for running and viewing the visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90a3f2-3bc1-446b-beff-4a02d84e72dd",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8e46b-e2fa-45a1-ab35-aaa1f3f2e0ff",
   "metadata": {
    "height": 79,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1799af",
   "metadata": {},
   "source": [
    "![crew flow](crewai_flow.png \"CrewAI Flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4aa2c-cbe5-49a4-8569-0fa8d2d59666",
   "metadata": {},
   "source": [
    "## **9\\. Executing the Flow** \n",
    "\n",
    "If all looks good, we’re ready to run the Flow to process leads through the entire pipeline. We use `nest_asyncio` to ensure the async execution works smoothly in a notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00316a-7d09-4533-af24-0842366e122f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "async def run_flow():\n",
    "    return flow.kickoff()\n",
    "\n",
    "emails = asyncio.run(run_flow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de4ee",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_text = emails[0].raw\n",
    "wrapped_text = textwrap.fill(result_text, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69752619-a9b6-4361-89d4-cbd35dbcb0c0",
   "metadata": {},
   "source": [
    "### Usage Metrics and Costs\n",
    "\n",
    "Let’s see how much it would cost each time if this crew runs at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2ad40-12a3-401f-ad32-6bd54a099734",
   "metadata": {
    "height": 215
   },
   "outputs": [],
   "source": [
    "# Lead qualification crew\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([flow.state[\"score_crews_results\"][0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "prompt_tokens = df_usage_metrics['prompt_tokens'].sum() \n",
    "completion_tokens = df_usage_metrics['completion_tokens'].sum()\n",
    "\n",
    "prompt_tokens_cost_usd_dollar, completion_tokens_cost_usd_dollar = cost_per_token(model=model, prompt_tokens=prompt_tokens, completion_tokens=completion_tokens)\n",
    "\n",
    "costs = prompt_tokens_cost_usd_dollar + completion_tokens_cost_usd_dollar \n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae27085-f186-40d2-84d8-3aad6ee8a322",
   "metadata": {
    "height": 215
   },
   "outputs": [],
   "source": [
    "# Email engagement crew\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([emails[0].token_usage.dict()])\n",
    "\n",
    "# Calculate total costs\n",
    "prompt_tokens = df_usage_metrics['prompt_tokens'].sum() \n",
    "completion_tokens = df_usage_metrics['completion_tokens'].sum()\n",
    "\n",
    "prompt_tokens_cost_usd_dollar, completion_tokens_cost_usd_dollar = cost_per_token(model=model, prompt_tokens=prompt_tokens, completion_tokens=completion_tokens)\n",
    "\n",
    "costs = prompt_tokens_cost_usd_dollar + completion_tokens_cost_usd_dollar \n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791302ad-20f0-45ab-bd0a-3edd6977a639",
   "metadata": {},
   "source": [
    "## **10\\. Inspecting the Results** \n",
    "\n",
    "Now, let’s examine the output to see how the leads were scored and what emails were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10efceb-e3fd-4324-9337-879be159f093",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scores = flow.state[\"score_crews_results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2976e",
   "metadata": {},
   "source": [
    "### View Lead Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860c745-0c7e-4edd-bf8b-75beb14f64bd",
   "metadata": {
    "height": 674
   },
   "outputs": [],
   "source": [
    "lead_scoring_result = scores[0].pydantic\n",
    "\n",
    "# Create a dictionary with the nested structure flattened\n",
    "data = {\n",
    "    'Name': lead_scoring_result.personal_info.name,\n",
    "    'Job Title': lead_scoring_result.personal_info.job_title,\n",
    "    'Role Relevance': lead_scoring_result.personal_info.role_relevance,\n",
    "    'Professional Background': lead_scoring_result.personal_info.professional_background,\n",
    "    'Company Name': lead_scoring_result.company_info.company_name,\n",
    "    'Industry': lead_scoring_result.company_info.industry,\n",
    "    'Company Size': lead_scoring_result.company_info.company_size,\n",
    "    'Revenue': lead_scoring_result.company_info.revenue,\n",
    "    'Market Presence': lead_scoring_result.company_info.market_presence,\n",
    "    'Lead Score': lead_scoring_result.lead_score.score,\n",
    "    'Scoring Criteria': ', '.join(lead_scoring_result.lead_score.scoring_criteria),\n",
    "    'Validation Notes': lead_scoring_result.lead_score.validation_notes\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient='index', columns=['Value'])\n",
    "\n",
    "# Reset the index to turn the original column names into a regular column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Rename the index column to 'Attribute'\n",
    "df = df.rename(columns={'index': 'Attribute'})\n",
    "\n",
    "# Create HTML table with bold attributes and left-aligned values\n",
    "html_table = df.style.set_properties(**{'text-align': 'left'}) \\\n",
    "                     .format({'Attribute': lambda x: f'<b>{x}</b>'}) \\\n",
    "                     .hide(axis='index') \\\n",
    "                     .to_html()\n",
    "\n",
    "# Display the styled HTML table\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1e303-6b10-4010-af59-54afa6a55f59",
   "metadata": {},
   "source": [
    "### **How Complex Can it Get?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a39a9216-103f-4a55-81ed-95a0ad41c73c",
   "metadata": {
    "height": 1201
   },
   "outputs": [],
   "source": [
    "class SalesPipeline(Flow):\n",
    "    \n",
    "  @start()\n",
    "  def fetch_leads(self):\n",
    "    # Pull our leads from the database\n",
    "    # This is a mock, in a real-world scenario, this is where you would\n",
    "    # fetch leads from a database\n",
    "    leads = [\n",
    "      {\n",
    "        \"lead_data\": {\n",
    "          \"name\": \"Kwasi Ankomah\",\n",
    "          \"job_title\": \"Architect\",\n",
    "          \"company\": \"Sambanova\",\n",
    "          \"email\": \"kwasi@sambanova.com\",\n",
    "          \"use_case\": \"Using AI Agent to do better data enrichment.\"\n",
    "        },\n",
    "      },\n",
    "    ]\n",
    "    return leads\n",
    "\n",
    "  @listen(fetch_leads)\n",
    "  def score_leads(self, leads):\n",
    "    scores = lead_scoring_crew.kickoff_for_each(leads)\n",
    "    self.state[\"score_crews_results\"] = scores\n",
    "    return scores\n",
    "\n",
    "  @listen(score_leads)\n",
    "  def store_leads_score(self, scores):\n",
    "    # Here we would store the scores in the database\n",
    "    return scores\n",
    "\n",
    "  @listen(score_leads)\n",
    "  def filter_leads(self, scores):\n",
    "    return [score for score in scores if score['lead_score'].score > 70]\n",
    "\n",
    "  @listen(and_(filter_leads, store_leads_score))\n",
    "  def log_leads(self, leads):\n",
    "    print(f\"Leads: {leads}\")\n",
    "\n",
    "  @router(filter_leads)\n",
    "  def count_leads(self, scores):\n",
    "    if len(scores) > 10:\n",
    "      return 'high'\n",
    "    elif len(scores) > 5:\n",
    "      return 'medium'\n",
    "    else:\n",
    "      return 'low'\n",
    "\n",
    "  @listen('high')\n",
    "  def store_in_salesforce(self, leads):\n",
    "    return leads\n",
    "\n",
    "  @listen('medium')\n",
    "  def send_to_sales_team(self, leads):\n",
    "    return leads\n",
    "\n",
    "  @listen('low')\n",
    "  def write_email(self, leads):\n",
    "    scored_leads = [lead.to_dict() for lead in leads]\n",
    "    emails = email_writing_crew.kickoff_for_each(scored_leads)\n",
    "    return emails\n",
    "\n",
    "  @listen(write_email)\n",
    "  def send_email(self, emails):\n",
    "    # Here we would send the emails to the leads\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900385f-10be-4f4b-aaa9-f1408b8b4be6",
   "metadata": {},
   "source": [
    "### Plotting the Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf2beb-818a-4db5-8338-280beac670b9",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "flow = SalesPipeline()\n",
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8a4df-a0cc-4aa5-a5cf-390792c7cec6",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "IFrame(src='./crewai_flow.html', width='150%', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d190d",
   "metadata": {},
   "source": [
    "## **Final Thoughts**\n",
    "\n",
    "In this notebook, we demonstrated how to build and orchestrate a multi-agent workflow using **CrewAI** and **SambaNova’s LLMs**. We accomplished key technical milestones, including:\n",
    "\n",
    "* **Modular Agent Design**: Defined agents and tasks using flexible YAML configurations, making it easy to adapt the workflow to different domains or use cases.  \n",
    "* **LLM Integration**: Leveraged **SambaNova's Meta-Llama 3.1 70B Instruct** model to power agents with high-speed inference and low-latency responses.  \n",
    "* **Tool Integration**: Combined agents with tools like web search and scraping to enrich tasks with real-time data.  \n",
    "* **Orchestrated Automation**: Used the **Crew** and **Flow** classes to create seamless, multi-step workflows with clear task delegation and output management.  \n",
    "* **Structured Outputs**: Implemented **Pydantic models** to ensure consistent and validated data outputs across tasks.  \n",
    "* **Workflow Visualization**: Generated visual representations of the flow to understand task dependencies and execution paths.  \n",
    "* **Cost Estimation**: Measured token usage and estimated costs to help gauge the efficiency of the workflow.\n",
    "\n",
    "These technical capabilities provide a blueprint for building scalable and customizable agentic workflows. Whether you’re automating data enrichment, research tasks, customer support, or content generation, you can easily define and modify agents, incorporate real-time tools, debug flows, and monitor performance and costs.\n",
    "\n",
    "By applying these principles, developers can automate sophisticated, multi-step processes, making their workflows more intelligent, adaptable, and efficient.\n",
    "\n",
    "### **Ready to Automate Your Own Use Case?**\n",
    "\n",
    "Start building with **SambaNova** and **CrewAI** today\\! For more information, check out the [SambaNova Cloud](https://cloud.sambanova.ai) Documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
